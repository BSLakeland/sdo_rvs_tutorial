{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SolAster Tutorial\n",
    "## EPRV6, Porto, \n",
    "### Ben Lakeland, University of Birmingham\n",
    "How to generate Sun-as-a-Star varaibles from SDO/HMI images\n",
    "\n",
    "Pipeline described in [Haywood et al. 2016](https://ui.adsabs.harvard.edu/abs/2016csss.confE..47H/abstract) and [Ervin et al. 2022](https://ui.adsabs.harvard.edu/abs/2022AJ....163..272E/abstractr)\n",
    "\n",
    "Github: [SolAster Github](https://github.com/tamarervin/SolAster)\n",
    "Website: [SolAster Website](https://tamarervin.github.io/SolAster/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "import SolAster.tools.rvs as rvs\n",
    "import SolAster.tools.calculation_funcs as sfuncs\n",
    "import SolAster.tools.lbc_funcs as lbfuncs\n",
    "import SolAster.tools.coord_funcs as ctfuncs\n",
    "import SolAster.tools.utilities as utils\n",
    "from SolAster.tools.settings import *\n",
    "from SolAster.tools.plotting_funcs import hmi_plot\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The SDO satellite](SDO.jpg)\n",
    "\n",
    "HMI scans a narrow (75 mA) range around the 6173 Fe I line.\n",
    "\n",
    "\n",
    "Produces ~1 arcsec resolved:\n",
    "- Line-of-sight velocity maps\n",
    "- Line-of sight magnetic field maps\n",
    "- Continuum intensity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading images with Sunpy\n",
    "\n",
    "Sunpy is a python package to access and make use of solar data.\n",
    "\n",
    "We will use it to download SDO images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each timestamp, we need to download a continuum intensity map, a Dopplergram, and a line-of-sight magnetogram, using the `search` function in `Fido`.\n",
    "\n",
    "Example use:\n",
    "```\n",
    "matching_images = Fido.search(\n",
    "    a.Time('2014-01-01T00:00:00', '2014-01-01T00:12:00'),\n",
    "    a.jsoc.Series('hmi.Ic_720s'),\n",
    "    a.jsoc.Notify('example@email.com')\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "`a.Time` specifies the time range in which we want to search for data. \n",
    "\n",
    "`a.jsoc.Series` tells jsoc which data products we want to access. In this case, we are getting the 720 second exposure (`720s`),  continuum intensitygrams (`Ic`) obtained from the Helioseismic and Magnetic Imager (`hmi`). The table below shows the relevant parameters to pass to `Series` for the data products we will be using.\n",
    "\n",
    "|Data type | jsoc Series |\n",
    "| ---- | --- |\n",
    "| Intensitygram | `hmi.Ic_720s`| \n",
    "| Magnetogram | `hmi.m_720s`| \n",
    "| Dopplergram | `hmi.v_720s`| \n",
    "\n",
    "\n",
    "\n",
    "`a.jsoc.Notify` tells jsoc which user is accessing the data, you will get a confirmation email each time you download the data.\n",
    "\n",
    "***If you don't have an account, you'll need to register your email [here](http://jsoc.stanford.edu/ajax/register_email.html)***\n",
    "\n",
    "Another useful parameter to pass to `search` includes, e.g., `a.Sample(12*u.hour)` if we wanted to only get data every 12 hours for the duration of the specified time range.\n",
    "\n",
    "Once we have identified all the matching available data products using `Fido.search`, we call\n",
    "\n",
    "```\n",
    "downloaded_files = Fido.fetch(matching_images, path='./path/{file}')\n",
    "```\n",
    "to download the relevant images, and save them in `./path/`. \n",
    "\n",
    "The `downloaded_files` object is a list of filepaths of the images.\n",
    "\n",
    "Make sure to change `your@email.com` to the email that you registered for the download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"your@email.com\"\n",
    "date_obs = datetime.datetime(2014, 1, 1, 0, 0, 0)\n",
    "continuum_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.Ic_720s'), a.jsoc.Notify(email))\n",
    "continuum_download = Fido.fetch(continuum_search, path='./sunpy_downloads/{file}')\n",
    "\n",
    "magnetogram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.m_720s'), a.jsoc.Notify(email))\n",
    "magnetogram_download = Fido.fetch(magnetogram_search, path='./sunpy_downloads/{file}')\n",
    "\n",
    "dopplergram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.V_720s'), a.jsoc.Notify(email))\n",
    "dopplergram_download = Fido.fetch(dopplergram_search, path='./sunpy_downloads/{file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above snippet, we are searching for files with timestamps between 2014-01-01T00:00:00 and 2014-01-01T00::00 (i.e., just short of the 720s cadence of the images). \n",
    "\n",
    "This ensures that we only fetch a single set of images, in practice we could have equally chosen 2014-01-01T00:00:00 and 2014-01-01T00:00:01 as the time range to search, whereas setting the upper limit as 2014-01-01T00:12:00 would fetch two sets of images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case no email was setup beforehand, the download is taking too long or `sunpy` is misbehaving as a whole, you can use the pre-downloaded images by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of emergency break glass\n",
    "bad_sunpy = True\n",
    "\n",
    "if bad_sunpy:\n",
    "    date_obs = datetime.datetime(2014, 1, 1, 0, 0, 0)\n",
    "    print('Using backup data')\n",
    "    all_files = os.listdir('./sunpy_downloads_backup/')\n",
    "    magnetogram_download = ['./sunpy_downloads_backup/' + i for i in all_files if 'magnetogram' in i]\n",
    "    continuum_download = ['./sunpy_downloads_backup/'+i for i in all_files if 'continuum' in i]\n",
    "    dopplergram_download = ['./sunpy_downloads_backup/' + i for i in all_files if 'Dopplergram' in i]\n",
    "\n",
    "\n",
    "jd_obs = Time(date_obs).jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_files = magnetogram_download + continuum_download + dopplergram_download\n",
    "\n",
    "print(downloaded_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving File Setup\n",
    "Here we generate the csv file in which we will be saving our data.\n",
    "\n",
    "We will use `panda DataFrames`. This is not a requirement and the preferred method of storing data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of csv file to store calculations\n",
    "csv_name = 'timeseries'\n",
    "\n",
    "# create file names\n",
    "current_position = Path().resolve()\n",
    "csv_file = os.path.join(current_position,csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(current_position,csv_name+'_bad_dates.csv')\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f', 'Bobs',\n",
    "                'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage', 'f_nonconv',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'unsigned_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "df = pd.DataFrame({i: [] for i in row_contents})\n",
    "df.to_csv(f'./{csv_name}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at the downloaded images\n",
    "\n",
    "We will now read the downloaded images. We will create three 2D arrays from the fits files:\n",
    "\n",
    "`imap`: Intensity map\n",
    "\n",
    "`vmap`: Doppler map\n",
    "\n",
    "`mmap`: Magnetic map\n",
    "\n",
    "\n",
    "These can be plotted with `pyplot.imshow()`. Here we just have a quick `.peek()` at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unusable file types\n",
    "good_files = []\n",
    "for file in downloaded_files:\n",
    "    name, extension = os.path.splitext(file)\n",
    "    if extension == '.fits':\n",
    "        good_files.append(file)\n",
    "\n",
    "# convert to map sequence\n",
    "map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "# check for missing data types\n",
    "missing_map = False\n",
    "# split into data types\n",
    "for j, map_obj in enumerate(map_seq):\n",
    "    if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "        vmap = map_obj\n",
    "    elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "        mmap = map_obj\n",
    "    elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "        imap = map_obj\n",
    "\n",
    "# coordinate transformation for maps\n",
    "x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "# remove bad mu values\n",
    "vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap])\n",
    "\n",
    "# quick peeks at the uncorrected images\n",
    "vmap.peek()\n",
    "mmap.peek(cmap='bwr')\n",
    "imap.peek(cmap='inferno')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, SDO doesn't have the long-term stability to let us directly measure the RV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A plot showing the instability of SDO](sdo_stability.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Corrections\n",
    "\n",
    "The downloaded images will require some correction before use.\n",
    "\n",
    "### Velocity Corrections\n",
    "\n",
    "To compute the actual surface velocity, we need to subtract from the Dopplergram the spacecraft velocity `vsc` and the solar rotational velocity `vrot`.\n",
    "\n",
    "We save the new corrected Dopplergram as `map_vel_corr` and take a peek at it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Velocity Corrections ######\n",
    "# calculate relative positions\n",
    "deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "# calculate spacecraft velocity\n",
    "vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "# optimized solar rotation parameters\n",
    "a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "# calculation of solar rotation velocity\n",
    "vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "# calculate corrected velocity\n",
    "corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "# corrected velocity maps\n",
    "map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "map_vel_cor.peek()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limb Darkening\n",
    "\n",
    "We flatten the intensitygram by dividing it by a limbdarkening polynomial.\n",
    "\n",
    "The u and v coefficients are taken from [Allen 1973](https://ui.adsabs.harvard.edu/abs/1973asqu.book.....A/abstract) based on the wavelength of SDO/HMI. `SolAster` computed the polynomial in the `limb_polynomial` function. Its output is an array of the same size as the maps.\n",
    "\n",
    "We save the flattened intensity map as `map_int_cor` and take a peek at it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Limb Darkening Corrections ######\n",
    "# limb brightening\n",
    "Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "# calculate corrected data\n",
    "Iflat = imap.data / Lij\n",
    "\n",
    "# corrected intensity maps\n",
    "map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "print(\"Before limb darkening correction:\")\n",
    "imap.peek(cmap='inferno')\n",
    "print(\"After limb darkening correction:\")\n",
    "map_int_cor.peek(cmap='inferno')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnetic Foreshortening\n",
    "\n",
    "We also include a correction for magnetic foreshortening. To do so we need to compute the unsigned magnetic field strength and magnetic noise. `SolAster` does so with the `mag_field` function.\n",
    "\n",
    "Using the `Br` output we can generate a map of the true radial magnetic field, saved as `map_mag_cor`. We take a peek at it here.\n",
    "\n",
    "We also include a bit of code to re-normalize and plot the magnetic field, for easier viewing.\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Magnetogram #####\n",
    "\n",
    "# calculate unsigned field strength to correct for foreshortening \n",
    "Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "# corrected observed magnetic data map\n",
    "map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "# true radial magnetic data map\n",
    "map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "#map_mag_obs.peek()\n",
    "map_mag_cor.peek(cmap='bwr')\n",
    "\n",
    "# to see a bit better\n",
    "normalize=True\n",
    "if normalize:\n",
    "    map_mag_cor.plot_settings['norm'] = plt.Normalize(-100, 100)\n",
    "    map_mag_cor.peek(cmap='bwr')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding threshold values\n",
    "\n",
    "We identify magnetic regions based on a magnetic cut-off value of 24 Gauss, taken from [Yeo et. al. 2013](https://ui.adsabs.harvard.edu/abs/2013A%26A...550A..95Y/abstract).\n",
    " \n",
    "\n",
    "We can now divide the Sun into _active_ and _inactive_ regions.\n",
    "\n",
    "Within these regions we can separate between bright active regions (which we can later further divide into network and plage/faculae) and dark active regions (spots). We map both into `fac_map` and `spot_map` and have a peek at them.\n",
    "\n",
    "We finally generate a single map that identifies both, `map_full_thresh`. We include a commented-out line at the end to plot our new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Find thresholds #####\n",
    "# calculate magnetic threshold\n",
    "#active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "active,quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "map_mag_thresh = sfuncs.corrected_map(active, mmap, map_type='Magnetic-Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "#map_mag_thresh.peek()\n",
    "\n",
    "\n",
    "\n",
    "# calculate intensity threshold\n",
    "fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "# create faculae map objects\n",
    "fac_map = sfuncs.corrected_map(fac_inds, mmap, map_type='Faculae', frame=frames.HeliographicCarrington)\n",
    "\n",
    "# create sunspot map objects\n",
    "spot_map = sfuncs.corrected_map(spot_inds, mmap, map_type='Sunspot', frame=frames.HeliographicCarrington)\n",
    "\n",
    "fac_map.peek()\n",
    "spot_map.peek()\n",
    "\n",
    "\n",
    "# create threshold array\n",
    "thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "# full threshold maps\n",
    "map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "\n",
    "\n",
    "\n",
    "hmi_plot(map_int_cor, map_mag_obs, map_vel_cor, fac_inds, spot_inds, mu, save_fig=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Factors\n",
    "\n",
    "From the identification of the active and inactive areas on the Sun we can now calculate the filling factors of bright regions and spots as a percentage of the total visible surface. To do so, `SolAster` uses the function `filling_factor`.\n",
    "\n",
    "To include the size dependence of the active regions, `SolAster` uses the function `area_filling_factor`. We can now derive the filling factors of plage and network separately (their sum will be equal to the bright region filling factor called `f_fac`). We can also derve the fraction of small to large active regions. This separation is introduced in Milbourne et al. 2019 and will be relevant when computing the radial velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute filling factors\n",
    "f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "print(f'Bright regions: {f_bright:.2f}%')\n",
    "print(f'Spots: {f_spot:.2f}%')\n",
    "\n",
    "### calculate the area filling factor\n",
    "pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "area = sfuncs.area_calc(active, pixA_hem)\n",
    "f_small, f_large, f_network, f_plage = sfuncs.area_filling_factor(active, area, mu, mmap,\n",
    "                                                                             fac_inds, athresh=Parameters.athresh,\n",
    "                                                                             mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "print(f'Plage or faculae regions: {f_plage:.2f}%')\n",
    "print(f'Bright Network: {f_network:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Velocity Derivation\n",
    "\n",
    "We here follow the radial velocity derivation explained in Haywood et al. 2016 and Milbourne et al. 2019.\n",
    "\n",
    "Radial velocities in SDO/HMI images are usually considered $\\Delta$ RVs, since they depend on the Quiet-sun velocity (the average velocity of the non-magnetically active areas of the Sun).\n",
    "\n",
    "The $\\Delta$ RVs are computed from a model, a linear combination of two components: `v_phot` and `v_conv`.\n",
    "\n",
    "`v_phot` is the velocity contribution due to the rotational Doppler imbalance generated by active regions. `v_conv` is the velocity contribution due to suppression of convective blueshift by active regions.\n",
    "\n",
    "`rv_model` = `A`x`v_phot`+`B`x`v_conv`+`RV0`\n",
    "\n",
    "The coefficients `A` and `B` depend on the telescope after which the SDO velocities are being normalized, and `RV0` is the required offset. We here explicitely list these values and in this tutorial we exclude the offset in the calculation to get the \"raw\" RV model. `SolAster` can directly compute the rv_model including offset with `calc_model`, depending on the selected instrument.\n",
    "\n",
    "Coefficients to match the HARPS-N wavelength range are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Radial Velocity Computations in m/s #####\n",
    "\n",
    "### velocity contribution due to convective motion of quiet-Sun\n",
    "v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "# calculate photospheric velocity\n",
    "v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "# calculate disc-averaged velocity\n",
    "v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "# calculate convective velocity\n",
    "v_conv = v_disc - v_quiet\n",
    "\n",
    "print(f'Photmetric velocity: {v_phot:.2f} m/s')\n",
    "print(f'Convective velocity: {v_conv:.2f} m/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARPS-N values\n",
    "A = 2.101\n",
    "B = 0.9825\n",
    "RV0 = 97.08\n",
    "\n",
    "\n",
    "#rv_model = rvs.calc_model(\"HARPS-N\", v_conv, v_phot)\n",
    "rv_model = A * v_phot + B * v_conv\n",
    "\n",
    "print(f'Derived radial velocity: {rv_model:.2f} m/s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetic Fluxes\n",
    "\n",
    "Studies such as [Haywood et al. 2022](https://ui.adsabs.harvard.edu/abs/2022ApJ...935....6H/abstract) and [Rescigno et al. (2024)](https://ui.adsabs.harvard.edu/abs/2024MNRAS.532.2741R/abstract) make use of the Sun-as-a-Star magnetic flux measurements derived from SDO/HMi images. We include how to compute them in the following section using the `SolAster` function `area_unsigned_flux`.\n",
    "\n",
    "Here the unsigned (absolute) magnetic flux is saved as `unsigned_obs_flux`, while the polarised (longitudinal) magnetic flux is `pol_flux`. Both are in Gauss.\n",
    "\n",
    "Other interesting values are: `quiet_flux` is the magnetic flux of the magnetically quiet regions, `ar_flux` the one of the magnetically active ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Magnetic Flux\n",
    "\n",
    "unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                        area,\n",
    "                                                                                        active,\n",
    "                                                                                    athresh=Parameters.athresh)\n",
    "\n",
    "### get area weighted convective velocities\n",
    "vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "\n",
    "print(f'Unsigned Magnetic Flux: {unsigned_obs_flux:.2f} G')\n",
    "print(f'Signed Magnetic Flux: {pol_flux:.2f} G')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data\n",
    "\n",
    "Now that we derived the main outputs of `SolAster`, we can save them. We again use `panda.DataFrame` to save to a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of what we want to save\n",
    "\n",
    "save_vals = {\n",
    "    \"date_obs\":date_obs.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "    \"date_jd\":jd_obs,\n",
    "    \"rv_model\":rv_model,\n",
    "     \"v_quiet\":v_quiet,\n",
    "     \"v_disc\":v_disc,\n",
    "     \"v_phot\":v_phot,\n",
    "     \"v_conv\":v_conv,\n",
    "     \"f_bright\":f_bright,\n",
    "     \"f_spot\":f_spot,\n",
    "     \"f\":f,\n",
    "     \"unsigned_obs_flux\":unsigned_obs_flux,\n",
    "     \"vphot_bright\":vphot_bright,\n",
    "     \"vphot_spot\":vphot_spot,\n",
    "     \"f_small\":f_small,\n",
    "     \"f_large\":f_large,\n",
    "     \"f_network\":f_network,\n",
    "     \"f_plage\":f_plage,\n",
    "     \"quiet_flux\":quiet_flux,\n",
    "     \"ar_flux\":ar_flux,\n",
    "     \"conv_flux\":conv_flux,\n",
    "     \"pol_flux\":pol_flux,\n",
    "     \"unsigned_flux\":unsigned_obs_flux,\n",
    "     \"pol_conv_flux\":pol_conv_flux,\n",
    "     \"vconv_quiet\":vconv_quiet,\n",
    "     \"vconv_large\":vconv_large,\n",
    "     \"vconv_small\":vconv_small\n",
    "}\n",
    "\n",
    "\n",
    "# save these values to the csv file\n",
    "df = pd.concat((df,pd.DataFrame(save_vals, index=[0])))\n",
    "df.to_csv(f'./{csv_name}.csv')\n",
    "# print that the date is completed\n",
    "print('\\nCalculations and save to file complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![Radial Velocity and Magnetic field time series](rv_timeseries.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have time to talk about all the exciting science we've done with SDO, but you can [read the papers here!](https://ui.adsabs.harvard.edu/user/libraries/ix1rqwgPTp2QBqJDqBkFPg)\n",
    "\n",
    "Also come and visit Poster #27"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating with multiple images\n",
    "\n",
    "Here we present the same process re-organized to be iterable, from data download to saving to file.\n",
    "\n",
    "We also present another way of featching data with Fido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"name@email.com\"\n",
    "date_obs = datetime.datetime(2014, 1, 1, 0, 0, 0)\n",
    "continuum_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:48:00'), a.jsoc.Series('hmi.Ic_720s'), a.jsoc.Notify(email))\n",
    "continuum_download = Fido.fetch(continuum_search, path='./multiple_images/{file}')\n",
    "\n",
    "magnetogram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:48:00'), a.jsoc.Series('hmi.m_720s'), a.jsoc.Notify(email))\n",
    "magnetogram_download = Fido.fetch(magnetogram_search, path='./multiple_images/{file}')\n",
    "\n",
    "dopplergram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:48:00'), a.jsoc.Series('hmi.V_720s'), a.jsoc.Notify(email))\n",
    "dopplergram_download = Fido.fetch(dopplergram_search, path='./multiple_images/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date range\n",
    "start_date = datetime.datetime(2014, 1, 1, 0, 0, 0)\n",
    "end_date = datetime.datetime(2014, 1, 1, 0, 48, )\n",
    "\n",
    "# query cadence in seconds (to download a single image per day, pick cadence = to a day)\n",
    "cadence = 720\n",
    "\n",
    "# get hmi data products\n",
    "time_range = datetime.timedelta(seconds=22)\n",
    "physobs_list = [a.Physobs.los_velocity, a.Physobs.los_magnetic_field, a.Physobs.intensity]\n",
    "\n",
    "# get dates list\n",
    "xy = (end_date - start_date).seconds + (end_date - start_date).days * 24 * 3600\n",
    "dates_list = [start_date + datetime.timedelta(seconds=cadence*x) for x in range(0, int(xy/cadence))]\n",
    "\n",
    "\n",
    "# name of csv file to store calculations\n",
    "csv_name = 'timeseries_iterated'\n",
    "\n",
    "# create file names\n",
    "current_position = Path().resolve()\n",
    "csv_file = os.path.join(current_position,csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(current_position,csv_name+'_bad_dates.csv')\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'rv_model', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f', 'Bobs',\n",
    "                'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage', 'f_nonconv',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'unsigned_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "df = pd.DataFrame({i: [] for i in row_contents})\n",
    "df.to_csv(f'./{csv_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './multiple_images/'\n",
    "\n",
    "A = 2.101\n",
    "B = 0.9825\n",
    "RV0 = 97.08\n",
    "\n",
    "\n",
    "for i, date in enumerate(dates_list):\n",
    "    # convert the date to a string -- required for use in csv file\n",
    "\n",
    "\n",
    "    date_str, date_obj, date_jd = utils.get_dates(date)\n",
    "\n",
    "    # # pull image within specified time range\n",
    "    # result = Fido.search(a.Time(str(date_obj - time_range), str(date_obj + time_range)),\n",
    "    #                     a.Instrument.hmi, physobs_list[0] | physobs_list[1] | physobs_list[2])\n",
    "\n",
    "    # # add file to list\n",
    "    # fido_download_path = os.path.join(current_position,\"sunpy_download/{file}\")\n",
    "    # file_download = Fido.fetch(result, path=fido_download_path)\n",
    "    \n",
    "    # remove unusable file types\n",
    "    \n",
    "\n",
    "    datestr = date_obj.strftime(\"%Y%m%d\")\n",
    "    timestr = date_obj.strftime(\"%H%M%S\")\n",
    "\n",
    "\n",
    "    dirlist = os.listdir(data_dir)\n",
    "\n",
    "    continuum_regex = re.compile(\n",
    "        f\"hmi.ic_720s.{datestr}_{timestr}_TAI.[1-9].continuum.fits\"\n",
    "    )\n",
    "    magnetogram_regex = re.compile(\n",
    "        f\"hmi.m_720s.{datestr}_{timestr}_TAI.[1-9].magnetogram.fits\"\n",
    "    )\n",
    "    dopplergram_regex = re.compile(\n",
    "        f\"hmi.v_720s.{datestr}_{timestr}_TAI.[1-9].Dopplergram.fits\"\n",
    "    )\n",
    "\n",
    "    continuum_match = list(filter(continuum_regex.match, dirlist))  # Read Note below\n",
    "    if len(continuum_match) != 1:\n",
    "        raise FileNotFoundError\n",
    "    continuum = data_dir + continuum_match[0]\n",
    "\n",
    "    dopplergram_match = list(\n",
    "        filter(dopplergram_regex.match, dirlist)\n",
    "    )  # Read Note below\n",
    "    if len(dopplergram_match) != 1:\n",
    "        raise FileNotFoundError\n",
    "    dopplergram = data_dir + dopplergram_match[0]\n",
    "\n",
    "    magnetogram_match = list(\n",
    "        filter(magnetogram_regex.match, dirlist)\n",
    "    )  # Read Note below\n",
    "    if len(magnetogram_match) != 1:\n",
    "        raise FileNotFoundError\n",
    "    magnetogram = data_dir + magnetogram_match[0]\n",
    "\n",
    "    good_files = [dopplergram, magnetogram, continuum]\n",
    "\n",
    "    # convert to map sequence\n",
    "    map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "    # check for missing data types\n",
    "    missing_map = False\n",
    "    # split into data types\n",
    "    for j, map_obj in enumerate(map_seq):\n",
    "        if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "            vmap = map_obj\n",
    "        elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "            mmap = map_obj\n",
    "        elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "            imap = map_obj\n",
    "        else:\n",
    "            missing_map = True\n",
    "\n",
    "    if missing_map:\n",
    "        print(\"Missing a data product for \" + date_str)\n",
    "\n",
    "        # add the data\n",
    "        # append these values to the csv file\n",
    "        save_vals = [date_str, 'missing data product']\n",
    "        continue\n",
    "\n",
    "\n",
    "    # coordinate transformation for maps\n",
    "    x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "    wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "    # remove bad mu values\n",
    "    vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap])\n",
    "\n",
    "    # calculate relative positions\n",
    "    deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "    # calculate spacecraft velocity\n",
    "    vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "    # optimized solar rotation parameters\n",
    "    a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "    # calculation of solar rotation velocity\n",
    "    vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "    # calculate corrected velocity\n",
    "    corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "    # corrected velocity maps\n",
    "    map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                        frame=frames.HeliographicCarrington)\n",
    "\n",
    "    # limb brightening\n",
    "    Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "    # calculate corrected data\n",
    "    Iflat = imap.data / Lij\n",
    "\n",
    "    # corrected intensity maps\n",
    "    map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                        frame=frames.HeliographicCarrington)\n",
    "\n",
    "    # calculate unsigned field strength\n",
    "    Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "    # corrected observed magnetic data map\n",
    "    map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                        frame=frames.HeliographicCarrington)\n",
    "\n",
    "    # radial magnetic data map\n",
    "    map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                        frame=frames.HeliographicCarrington)\n",
    "\n",
    "    # calculate magnetic threshold\n",
    "    active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "    # calculate intensity threshold\n",
    "    fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "    # create threshold array\n",
    "    thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "    # full threshold maps\n",
    "    map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                            frame=frames.HeliographicCarrington)\n",
    "\n",
    "\n",
    "    ### velocity contribution due to convective motion of quiet-Sun\n",
    "    v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "    ### velocity contribution due to rotational Doppler imbalance of active regions (faculae/sunspots)\n",
    "    # calculate photospheric velocity\n",
    "    v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "    ### velocity contribution due to suppression of convective blueshift by active regions\n",
    "    # calculate disc-averaged velocity\n",
    "    v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "\n",
    "    # calculate convective velocity\n",
    "    v_conv = v_disc - v_quiet\n",
    "\n",
    "    ### filling factor\n",
    "    # calculate filling factor\n",
    "    f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "    ### unsigned magnetic flux\n",
    "    # unsigned observed flux\n",
    "    unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "    ### calculate the area filling factor\n",
    "    pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "    area = sfuncs.area_calc(active, pixA_hem)\n",
    "    f_small, f_large, f_network, f_plage = sfuncs.area_filling_factor(active, area, mu, mmap,\n",
    "                                                                                    fac_inds, athresh=Parameters.athresh,\n",
    "                                                                                    mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "    ### get the unsigned flux\n",
    "    quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                            area,\n",
    "                                                                                            active,\n",
    "                                                                                        athresh=Parameters.athresh)\n",
    "\n",
    "    ### get area weighted convective velocities\n",
    "    vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "\n",
    "    ### calculate model RV\n",
    "    rv_model = rv_model = A * v_phot + B * v_conv\n",
    "    \n",
    "    save_vals = {\n",
    "        \"date_obs\": date_str,\n",
    "        \"date_jd\": date_jd,\n",
    "        \"rv_model\":rv_model,\n",
    "        \"v_quiet\":v_quiet,\n",
    "        \"v_disc\":v_disc,\n",
    "        \"v_phot\":v_phot,\n",
    "        \"v_conv\":v_conv,\n",
    "        \"f_bright\":f_bright,\n",
    "        \"f_spot\":f_spot,\n",
    "        \"f\":f,\n",
    "        \"unsigned_obs_flux\":unsigned_obs_flux,\n",
    "        \"vphot_bright\":vphot_bright,\n",
    "        \"vphot_spot\":vphot_spot,\n",
    "        \"f_small\":f_small,\n",
    "        \"f_large\":f_large,\n",
    "        \"f_network\":f_network,\n",
    "        \"f_plage\":f_plage,\n",
    "        \"quiet_flux\":quiet_flux,\n",
    "        \"ar_flux\":ar_flux,\n",
    "        \"conv_flux\":conv_flux,\n",
    "        \"pol_flux\":pol_flux,\n",
    "        \"unsigned_flux\":unsigned_obs_flux,\n",
    "        \"pol_conv_flux\":pol_conv_flux,\n",
    "        \"vconv_quiet\":vconv_quiet,\n",
    "        \"vconv_large\":vconv_large,\n",
    "        \"vconv_small\":vconv_small\n",
    "        }\n",
    "\n",
    "\n",
    "    # save these values to the csv file\n",
    "    ######### check for index!!!!\n",
    "    df = pd.concat((df,pd.DataFrame(save_vals, index=[0])))\n",
    "    df.to_csv(f'./{csv_name}.csv')\n",
    "\n",
    "    # print that the date is completed\n",
    "    print('\\nCalculations and save to file complete for ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "print('Calculation complete for dates:', start_date, 'to', end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdo_rvs_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
